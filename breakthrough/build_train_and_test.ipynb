{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from nlrl.utils import write_jsonl, read_jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging state dataset, and split it into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test set 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = './rollout_collection_5x5'\n",
    "data_list = os.listdir(root_dir)\n",
    "\n",
    "final_data_list = []\n",
    "for path in data_list:\n",
    "    data_path = os.path.join(root_dir, path, 'replay_buffer.jsonl')\n",
    "    final_data_list.append(data_path)\n",
    "\n",
    "merged_data = []\n",
    "for path in final_data_list:\n",
    "    merged_data.extend(read_jsonl(path))\n",
    "\n",
    "full_states = []\n",
    "for d in merged_data:\n",
    "    full_states.extend(d['serializad_state'])\n",
    "print(len(full_states))\n",
    "full_states = set(full_states)\n",
    "print(len(full_states))\n",
    "full_states = list(filter(lambda x: x != 'Terminal State.', full_states))\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "evaluation = np.random.choice(full_states, 3000, replace=False)\n",
    "evaluation_data = [{'serializad_state': e} for e in evaluation]\n",
    "\n",
    "save_dir = './rollout_collection_5x5_processed/evaluation_3000'\n",
    "write_jsonl(evaluation_data, os.path.join(save_dir, 'merged_initial_state.jsonl'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train set by removing 3000 test states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = './rollout_collection_5x5'\n",
    "data_list = os.listdir(root_dir)\n",
    "evaluation = read_jsonl('./rollout_collection_5x5_processed/evaluation_3000/merged_initial_state.jsonl')\n",
    "evaluation = [e['serializad_state'] for e in evaluation]\n",
    "\n",
    "final_data_list = []\n",
    "for path in data_list:\n",
    "    data_path = os.path.join(root_dir, path, 'replay_buffer.jsonl')\n",
    "    final_data_list.append(data_path)\n",
    "\n",
    "merged_data = []\n",
    "for path in final_data_list:\n",
    "    merged_data.extend(read_jsonl(path))\n",
    "\n",
    "full_states = []\n",
    "for d in merged_data:\n",
    "    full_states.extend(d['serializad_state'])\n",
    "print(len(full_states))\n",
    "full_states = set(full_states)\n",
    "print(len(full_states))\n",
    "evaluation_ref = set(evaluation)\n",
    "full_states = [f for f in full_states if not f in evaluation_ref]\n",
    "print(len(full_states))\n",
    "training_data = [{'serializad_state': e} for e in full_states]\n",
    "\n",
    "save_dir = './rollout_collection_5x5_processed/train_without_eval_3000'\n",
    "\n",
    "config = [{\"comment\": \"This is the merged deduplicated state data without 3000 held-out evaluation set\"}]\n",
    "write_jsonl(config, os.path.join(save_dir, 'config.jsonl'), overwrite=True)\n",
    "write_jsonl(training_data, os.path.join(save_dir, 'merged_initial_state.jsonl'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsample 1/40 dataset, around 10k unique states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = './rollout_collection_5x5'\n",
    "save_dir = './rollout_collection_5x5_processed/sample_1_40'\n",
    "\n",
    "train_set = read_jsonl('./rollout_collection_5x5_processed/train_without_eval_3000/merged_initial_state.jsonl')\n",
    "\n",
    "import numpy as np\n",
    "seed = 42\n",
    "ratio = 0.025\n",
    "np.random.seed(seed)\n",
    "merged_data = np.random.choice(train_set, int(ratio * len(train_set)), replace=False)\n",
    "print(len(merged_data))\n",
    "\n",
    "config = [{\"seed\": seed, \"ratio\": ratio}]\n",
    "write_jsonl(config, os.path.join(save_dir, 'config.jsonl'), overwrite=True)\n",
    "write_jsonl(merged_data, os.path.join(save_dir, 'merged_initial_state.jsonl'), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
